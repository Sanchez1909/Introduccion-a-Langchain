{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAG Apps\n",
    "\n",
    "## ¿Que son las RAG Apps?\n",
    "\n",
    "Las RAG (Retrieval Augmented Generation) Apps son aplicaciones que nos permiten ajustar modelos de lenguajes a un contexto en especifico, en este caso lo que se busca es tener un documento que le agregara contexto a nuestro modelo para que sea un poco mas conciente sobre de lo que se esta hablando. \n",
    "¿Por que se hace esto?, aunque los datos de entrenamiento de un modelo son grandisimos, puede que nosotros estemos interesados en algo muy especifico, como un local o algun tema sobre el que no ha sido entrenado, o tal vez lo que buscamos es que se comporte de tal manera, que pareciera que estamos charlando con el documento.\n",
    "\n",
    "## Para refrescar la memoria\n",
    "\n",
    "### Que son los embeddings\n",
    "\n",
    "Son representaciones vectoriales densas de datos (estos normalmente son palabras, frases, parrafos e incluso en este caso, documentos) en un espacio de dimensión reducida que capturan las caracteristicas semanticas y sintacticas de las entidades que representan.\n",
    "\n",
    "- Densidad\n",
    "    El vector tiene valor en cada una de sus dimensiones.\n",
    "- Dimensionalidad reducida\n",
    "    Los vectores tienen una dimensionalidad fija, menor al vocabulario conocido.\n",
    "- Distribucion semantica\n",
    "    Se organizan de tal manera que aquellos que son similares, se encuentran mas cercanos entre si.\n",
    "\n",
    "Podemos ver una representacion mas grafica a traves del siguiente link: [Embedding Projector](https://projector.tensorflow.org/)\n",
    "\n",
    "## ¿Como es el proceso?\n",
    "\n",
    "<center><img src=\"Imagenes/VectoreStore.png\" width=\"750\" height=\"375\" ></center>\n",
    "\n",
    "1. **Load :** Este proceso comienza desde que se cargan los documentos. Los documentos que son cargados seran utilizados como contexto para nuestra aplicacion.\n",
    "2. **Chunking :** Una de las partes mas importantes del proceso es el troceo o chunking, durante este proceso lo que se busca es dividir el documento en pedazos mas pequeños para posteriarmente pasarlas por un modelo especializado en embeddings y que sean almacenados.\n",
    "Existen diferentes metodos para realizar el chunking:\n",
    "    - Fixed size (Tamaño fijo).\n",
    "    - Recursive (Recursivo).\n",
    "    - Document specific (Centrado en tipo de documento).\n",
    "    - Semantic based (Basado en relevancia semantica).\n",
    "        - Consultando el siguiente [link](https://huggingface.co/spaces/m-ric/chunk_visualizer) puedes visualizar de manera mas grafica algunos metodos de chunking.\n",
    "3. **Embedding :** Los trozos generados se pasan por un modelo de embeddings, que como se menciono antes, son representaciones vectoriales que pueden colocarse de tal manera, que estos esten mas cerca entre si, segun su similitud.\n",
    "4. **Store :** Los embeddings se almacenan en una base vectorial, estos permaneceran aqui hasta el momento en que sean llamados en una consulta para agregar valor contextual en la respuesta.\n",
    "\n",
    "\n",
    "<center><img src=\"Imagenes/RAG App.png\" width=\"750\" height=\"375\"></center>\n",
    "\n",
    "5. **Question :** Una vez realizado todo el proceso de almacenado y procesado de la informacion contextual, pasamos al proceso de la generacion de una respuesta, iniciando por el procesamiento de la pregunta.\n",
    "\n",
    "6. **Retrieve :** Despues de procesar la pregunta, el programa accede a la base de datos vectoriales y recupera los chunks con un valor contextual mas valiosos, para que estos en una etapa posterior sean utilizados.\n",
    "\n",
    "7. **Prompt :** El flujo del programa se dirige al prompt, donde el modelo verifica el comportamiento que este debe tomar.\n",
    "\n",
    "8. **LLM :** Tanto el prompt, como los chunks, son anexados para que el modelo comienza con la generacion de una respuesta.\n",
    "\n",
    "9. **Answer :** Finalmente termianos en la obtencion de una respuesta contextualizada gracias al documento anexado al principio.\n",
    "\n",
    "A continuacion se muestra un ejemplo sencillo de una RAG App:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~ip (C:\\Users\\ilike\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ip (C:\\Users\\ilike\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ip (C:\\Users\\ilike\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages)\n",
      "\n",
      "[notice] A new release of pip is available: 25.0 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
      "WARNING: Ignoring invalid distribution ~ip (C:\\Users\\ilike\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages)\n",
      "ERROR: Could not find a version that satisfies the requirement nest_ansyncio (from versions: none)\n",
      "\n",
      "[notice] A new release of pip is available: 25.0 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
      "ERROR: No matching distribution found for nest_ansyncio\n",
      "WARNING: Ignoring invalid distribution ~ip (C:\\Users\\ilike\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ip (C:\\Users\\ilike\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ip (C:\\Users\\ilike\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages)\n",
      "\n",
      "[notice] A new release of pip is available: 25.0 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
      "WARNING: Ignoring invalid distribution ~ip (C:\\Users\\ilike\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ip (C:\\Users\\ilike\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ip (C:\\Users\\ilike\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages)\n",
      "\n",
      "[notice] A new release of pip is available: 25.0 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
      "WARNING: Ignoring invalid distribution ~ip (C:\\Users\\ilike\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ip (C:\\Users\\ilike\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ip (C:\\Users\\ilike\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages)\n",
      "\n",
      "[notice] A new release of pip is available: 25.0 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
      "WARNING: Ignoring invalid distribution ~ip (C:\\Users\\ilike\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ip (C:\\Users\\ilike\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ip (C:\\Users\\ilike\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages)\n",
      "\n",
      "[notice] A new release of pip is available: 25.0 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
      "WARNING: Ignoring invalid distribution ~ip (C:\\Users\\ilike\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ip (C:\\Users\\ilike\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ip (C:\\Users\\ilike\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages)\n",
      "\n",
      "[notice] A new release of pip is available: 25.0 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
      "WARNING: Ignoring invalid distribution ~ip (C:\\Users\\ilike\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ip (C:\\Users\\ilike\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ip (C:\\Users\\ilike\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages)\n",
      "\n",
      "[notice] A new release of pip is available: 25.0 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install asyncio -q\n",
    "!pip install nest_ansyncio -q\n",
    "!pip install langchain_community -q\n",
    "!pip install langchain_text_splitters -q\n",
    "!pip install langchain_ollama -q\n",
    "!pip install langchain_chroma -q\n",
    "!pip install langchain_core -q\n",
    "!pip install IPython -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "import nest_asyncio\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_ollama import OllamaEmbeddings, ChatOllama\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from IPython.display import clear_output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Durante esta fase, se establece la informacion que aportara valor contextual."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Habilitar el soporte async en Jupyter\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# Carga y divide los documentos\n",
    "loader = WebBaseLoader(\"https://cgsait.udg.mx/es/cads#:~:text=LEO%20%C3%81TROX%2C%20superc%C3%B3mputo%20a%20tu,poder%20de%20procesamiento%20de%20datos.&text=150%20nodos%20c%C3%B3mputo%2C%20con%20un,c%C3%B3mputo%20con%20tecnolog%C3%ADa%20XEON%20PHI%20.\")\n",
    "data = loader.load()\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=300, chunk_overlap=0)\n",
    "all_splits = text_splitter.split_documents(data)\n",
    "\n",
    "# Configuración de embeddings y vectorstore\n",
    "local_embeddings = OllamaEmbeddings(model=\"nomic-embed-text:latest\")\n",
    "vectorstore = Chroma.from_documents(documents=all_splits, embedding=local_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Establecemos el comportamiento del modelo (El modelo que se estara usando, definicion de un prompt template, anexamos la informacion contextual y creamos la cadena)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuración del modelo de lenguaje y plantilla de RAG\n",
    "model = ChatOllama(model=\"llama3.2:latest\")  # Cambiado a llama2 por compatibilidad\n",
    "\n",
    "RAG_TEMPLATE = \"\"\"\n",
    "Eres un asiste de preguntas y respuestas. Usa la informacion recuperada para contestar las preguntas, relacionadas al CADS. Si no sabes la respuesta, solo di que no conoces la respuesta. Usa tres sentencias como maximo para dar una respuesta concisa.\n",
    "\n",
    "<context>\n",
    "{context}\n",
    "</context>\n",
    "\n",
    "Contesta la siguiente pregunta: \n",
    "\n",
    "{question}\"\"\"\n",
    "\n",
    "rag_prompt = ChatPromptTemplate.from_template(RAG_TEMPLATE)\n",
    "\n",
    "# Definir la función para formatear documentos\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "chain = (\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | rag_prompt\n",
    "    | model\n",
    "    | StrOutputParser()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalmente solo quedaria realizar preguntas relacionadas al documento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para manejar una sola pregunta\n",
    "async def process_question(question):\n",
    "    print(f\"Procesando pregunta: {question}\\n\")\n",
    "    response = \"\"\n",
    "    try:\n",
    "        async for chunk in chain.astream(question):\n",
    "            response += chunk\n",
    "            clear_output(wait=True)\n",
    "            print(f\"Pregunta: {question}\")\n",
    "            print(f\"Respuesta: {response}\", flush=True)\n",
    "        return response\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "# Función para ejecutar la pregunta\n",
    "def run_single_question(question):\n",
    "    return asyncio.get_event_loop().run_until_complete(process_question(question))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pregunta: De que habla el documento?\n",
      "Respuesta: El documento menciona los servicios ofrecidos por CADS, como procesamiento de datos e imágenes, configuración de aplicaciones científicas, desarrollo y optimización de código, modelado de paralelización de software, soluciones para análisis de grandes volúmenes de datos (Big Data) y visualización científica. También se menciona la posibilidad de servicios de consultoría para proyectos de investigación y capacitación.\n"
     ]
    }
   ],
   "source": [
    "respuesta=run_single_question(\"De que habla el documento?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
