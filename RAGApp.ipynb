{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAG Apps\n",
    "\n",
    "## ¿Que son las RAG Apps?\n",
    "\n",
    "Las RAG (Retrieval Augmented Generation) Apps son aplicaciones que nos permiten ajustar modelos de lenguajes a un contexto en especifico, en este caso lo que se busca es tener un documento que le agregara contexto a nuestro modelo para que sea un poco mas conciente sobre de lo que se esta hablando. \n",
    "¿Por que se hace esto?, aunque los datos de entrenamiento de un modelo son grandisimos, puede que nosotros estemos interesados en algo muy especifico, como un local o algun tema sobre el que no ha sido entrenado, o tal vez lo que buscamos es que se comporte de tal manera, que pareciera que estamos charlando con el documento.\n",
    "\n",
    "## Para refrescar la memoria\n",
    "\n",
    "### Que son los embeddings\n",
    "\n",
    "Son representaciones vectoriales densas de datos (estos normalmente son palabras, frases, parrafos e incluso en este caso, documentos) en un espacio de dimensión reducida que capturan las caracteristicas semanticas y sintacticas de las entidades que representan.\n",
    "\n",
    "- Densidad\n",
    "    El vector tiene valor en cada una de sus dimensiones.\n",
    "- Dimensionalidad reducida\n",
    "    Los vectores tienen una dimensionalidad fija, menor al vocabulario conocido.\n",
    "- Distribucion semantica\n",
    "    Se organizan de tal manera que aquellos que son similares, se encuentran mas cercanos entre si.\n",
    "\n",
    "Podemos ver una representacion mas grafica a traves del siguiente link: [Embedding Projector](https://projector.tensorflow.org/)\n",
    "\n",
    "## ¿Como es el proceso?\n",
    "\n",
    "<img src=\"Imagenes/VectoreStore.png\" width=\"1000\" height=\"500\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "import nest_asyncio\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_ollama import OllamaEmbeddings, ChatOllama\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from IPython.display import clear_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Habilitar el soporte async en Jupyter\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# Carga y divide los documentos\n",
    "loader = WebBaseLoader(\"https://cgsait.udg.mx/es/cads#:~:text=LEO%20%C3%81TROX%2C%20superc%C3%B3mputo%20a%20tu,poder%20de%20procesamiento%20de%20datos.&text=150%20nodos%20c%C3%B3mputo%2C%20con%20un,c%C3%B3mputo%20con%20tecnolog%C3%ADa%20XEON%20PHI%20.\")\n",
    "data = loader.load()\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=300, chunk_overlap=0)\n",
    "all_splits = text_splitter.split_documents(data)\n",
    "\n",
    "# Configuración de embeddings y vectorstore\n",
    "local_embeddings = OllamaEmbeddings(model=\"nomic-embed-text:latest\")\n",
    "vectorstore = Chroma.from_documents(documents=all_splits, embedding=local_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuración del modelo de lenguaje y plantilla de RAG\n",
    "model = ChatOllama(model=\"llama3.2:latest\")  # Cambiado a llama2 por compatibilidad\n",
    "\n",
    "RAG_TEMPLATE = \"\"\"\n",
    "Eres un asiste de preguntas y respuestas. Usa la informacion recuperada para contestar las preguntas, relacionadas al CADS. Si no sabes la respuesta, solo di que no conoces la respuesta. Usa tres sentencias como maximo para dar una respuesta concisa.\n",
    "\n",
    "<context>\n",
    "{context}\n",
    "</context>\n",
    "\n",
    "Contesta la siguiente pregunta: \n",
    "\n",
    "{question}\"\"\"\n",
    "\n",
    "rag_prompt = ChatPromptTemplate.from_template(RAG_TEMPLATE)\n",
    "\n",
    "# Definir la función para formatear documentos\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "chain = (\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | rag_prompt\n",
    "    | model\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "# Función para manejar una sola pregunta\n",
    "async def process_question(question):\n",
    "    print(f\"Procesando pregunta: {question}\\n\")\n",
    "    response = \"\"\n",
    "    try:\n",
    "        async for chunk in chain.astream(question):\n",
    "            response += chunk\n",
    "            clear_output(wait=True)\n",
    "            print(f\"Pregunta: {question}\")\n",
    "            print(f\"Respuesta: {response}\", flush=True)\n",
    "        return response\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "# Función para ejecutar la pregunta\n",
    "def run_single_question(question):\n",
    "    return asyncio.get_event_loop().run_until_complete(process_question(question))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pregunta: Cual es la mision del CADS\n",
      "Respuesta: No conocemos la misión específica del CADS, pero según su descripción, su propósito es \"posibilitar y acelerar las investigaciones científicas y el desarrollo tecnológico de la comunidad universitaria\". También se menciona que está adscrito a la CGSAIT desde 2019.\n"
     ]
    }
   ],
   "source": [
    "respuesta=run_single_question(\"Cual es la mision del CADS\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
