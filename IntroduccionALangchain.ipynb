{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduccion a Langchain\n",
    "\n",
    "## Antes de comenzar...\n",
    "\n",
    "Durante a lo largo de este repositorio estare hablando acerca de lo aprendido en langchain y como estuve trabajando con el, es por ello que sera necesario correr los modelos de manera local.\n",
    "En este caso estaremos haciendo el uso de Ollama y estaremos descargando algunos modelos segun se vayan necesitando.\n",
    "Para consultar mas informacion acerca de Ollama presiona [aqui.](https://github.com/Sanchez1909/Introduccion-a-Langchain/blob/main/Ollama/Ollama.md)\n",
    "\n",
    "## Componentes esenciales\n",
    "\n",
    "Para llevar poder llevar acabo este curso, sera necesario tener instalado:\n",
    "- Visual Studio Code\n",
    "- Ollama\n",
    "    - nomic-embed-text (Nos servira para trabajar con los embeddings)\n",
    "    - llama3.2 / deepseek-r1:1.5b\n",
    "- Python\n",
    "- Jupyter Notebook/Google Colab\n",
    "\n",
    "---\n",
    "\n",
    "## Navegando por langchain\n",
    "\n",
    "En estos momentos, estaremos navegando por diferentes componentes de langchain para poder conocer sus diversas funcionalidades y poder trabajar con la biblioteca.\n",
    "\n",
    "---\n",
    "\n",
    "### LLM Wrappers\n",
    "\n",
    "Estos componentes son abstracciones que encapsulan la interaccion con modelos de lenguaje de gran escala (LLM), facilitando la integracion de estos modelos en nuestras aplicaciones y añadiendoles diversas funcionalidades."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain_ollama -q\n",
    "!pip install langchain_community -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ollama \n",
    "from langchain_ollama import ChatOllama \n",
    "from langchain_community.llms import Ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'¡Claro! Aquí tienes uno:\\n\\n¿Por qué la computadora fue al doctor?\\n\\n¡Porque tenía un virus!\\n\\nEspero que te haya hecho sonreír. ¿Quieres escuchar otro?'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm =  Ollama(model= \"llama3.2\")\n",
    "\n",
    "respuesta = llm.invoke(\"Cuentame un chiste\")\n",
    "\n",
    "respuesta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chat Models\n",
    "\n",
    "Este componente es un tipo especializado de modelo de lenguaje que procesa y responde a entradas en formato de mensajes de chat, en lugar de texto plano."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'¡Claro! Aquí tienes uno:\\n\\n¿Por qué la computadora fue al doctor?\\n\\nPorque tenía un virus!\\n\\nEspero que te haya hecho sonreír. ¿Quieres escuchar otro?'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llmChat = ChatOllama(model=\"llama3.2\")\n",
    "\n",
    "respuesta = llm.invoke(\"Cuentame un chiste\")\n",
    "\n",
    "respuesta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Importante tener en cuenta que el tiempo de procesamiento de la respuesta depende de la capacidad de nuestra computadora y del tamaño del modelo.\n",
    "\n",
    "### Prompt Templates\n",
    "\n",
    "Los Prompt Templates son plantillas que nos facilitan la generacion de prompts para poder unirlos con los modelos de lenguaje y conseguir resultados mas especificos.\n",
    "\n",
    "Son muy utilices, ya que son bastante flexibles y nos permiten que la necesidad de su rediseño sea minima."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Dime algo gracioso sobre los oso'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "promptTemplate = PromptTemplate.from_template(\n",
    "    \"Dime algo {adjetivo} sobre {tema}\"\n",
    ")\n",
    "\n",
    "promptTemplate.format(adjetivo=\"gracioso\",tema= \"los oso\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chains \n",
    "\n",
    "- Permiten secuenciar tareas y procesos en un flujo de trabajo definido\n",
    "- Hacen que la interaccion entre un componente y una herramienta sea mas facil\n",
    "- Permiten una mejor optimizacion de tareas complejas y multifáceticas. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = promptTemplate | llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'¡Claro! Aquí te dejo una historia graciosa sobre osos:\\n\\nEn un bosque lleno de árboles altos y senderos sinuados, vivía un oso llamado Ollie. Ollie era conocido por su peculiaridad: cada vez que se sentía ansioso o nervioso, solía hacer una baileta extraña con sus patas.\\n\\nUn día, mientras Ollie estaba recorriendo el bosque en busca de comida, se topó con un grupo de osos jóvenes que estaban discutiendo sobre quién era el mejor bailarín del bosque. Los osos jóvenes habían escuchado hablar de Ollie y su baileta y decidieron investigar.\\n\\nCuando los osos jóvenes se acercaron a Ollie, éste les dijo: \"Sí, soy el mejor bailarín del bosque. Mi baileta es la más perfecta y mi pasión por la danza es inigualable\".\\n\\nLos osos jóvenes se miraron entre sí con sorpresa y preguntaron: \"¿Cómo haces eso? ¿Te entrenaste?\"\\n\\nOllie respondió: \"Sí, me entrené durante años en el arte de hacer una baileta sin que nadie lo note. ¡Y puedo hacerlo mientras estoy comiendo también!\"\\n\\nLos osos jóvenes se rieron y dijeron: \"Eso es imposible! No puedes comer y bailar al mismo tiempo\".\\n\\nPero Ollie les demostró su habilidad, comenzando a comer una manzana y al mismo tiempo hacer una baileta perfecta. Los osos jóvenes quedaron impresionados y se unieron a él en la pista de baile.\\n\\nJuntos, Ollie y los osos jóvenes bailaron durante horas, comiendo y riendo mientras lo hacían. Y desde ese día, Ollie fue conocido como el mejor bailarín del bosque y su baileta se convirtió en un espectáculo popular entre la comunidad de osos.\\n\\n¡Espero que te haya gustado!'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"adjetivo\": \"gracioso\",\"tema\": \"los osos\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Memoria\n",
    "\n",
    "- Mejora la capacidad del sistema para recordar interacciones previas\n",
    "- Permite que las generaciones de respuestas sean mas precisas y esten contextualizadas\n",
    "- Crucial para aplicaciones con interacciones a largo plazo.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain_core -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_ollama import ChatOllama \n",
    "\n",
    "model = ChatOllama(model=\"llama3.2\")\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"Eres un asistente de IA que se especializa en {habilidad}. Trata de responder todas las preguntas que esten relacionadas sobre {habilidad}\"\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=\"historial\"),\n",
    "        (\n",
    "            \"human\",\n",
    "            \"{entrada}\"\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "chainHistory = prompt | model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "\n",
    "sesiones = {}\n",
    "\n",
    "def verificarSesionHistorial(session_id: str) -> BaseChatMessageHistory:\n",
    "    if session_id not in sesiones:\n",
    "        sesiones[session_id] = ChatMessageHistory()\n",
    "    return sesiones[session_id]\n",
    "\n",
    "modeloConHistorial = RunnableWithMessageHistory(\n",
    "    chainHistory,\n",
    "    verificarSesionHistorial,\n",
    "    input_messages_key=\"entrada\",\n",
    "    history_messages_key=\"historial\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Los embeddings, también conocidos como vectores de representación o vectores de espacio de datos, son una técnica utilizada en la inteligencia artificial y el aprendizaje automático. Fue introducida por primera vez en 2013 por el equipo de researchers liderado por Quoc V. Le, durante su investigación sobre redes neuronales con convoluciones.\\n\\n**¿Qué es un embedding?**\\n\\nUn embedding es una transformación lineal que se aplica a un vector de entrada (como un documento de texto o una imagen) para reducir su dimensión a un espacio de datos más bajo y comprensible. En otras palabras, un embedding intenta capturar la esencia o el significado de los datos originales en un nuevo espacio de datos.\\n\\n**Características de los embeddings**\\n\\nLos embeddings tienen varias características importantes:\\n\\n1.  **Reducción de dimensionalidad**: Los embeddings reducen la dimensión de los datos originales, lo que hace más fácil el procesamiento y el almacenamiento de grandes conjuntos de datos.\\n2.  **Representación de significado**: Los embeddings intentan capturar el significado o la esencia de los datos originales en un nuevo espacio de datos.\\n3.  **Diferenciación**: Los embeddings son diferenciables, lo que significa que se puede calcular su derivada (gradiente) para minimizar una función de pérdida durante la entrenamiento.\\n\\n**Tipos de embeddings**\\n\\nExisten varios tipos de embeddings, incluyendo:\\n\\n1.  **Vector espacial**: Un tipo de embedding que representa los datos como vectores en un espacio de dimensionalidad fija.\\n2.  **Eje espacial**: Un tipo de embedding que busca minimizar la distancia entre dos puntos en el espacio de datos originales.\\n\\n**Aplicaciones de los embeddings**\\n\\nLos embeddings tienen muchas aplicaciones en el aprendizaje automático y otras áreas, incluyendo:\\n\\n1.  **Reconocimiento de patrones**: Los embeddings se pueden utilizar para reconocer patrones en grandes conjuntos de datos.\\n2.  **Clasificación**: Los embeddings se pueden utilizar como características para la clasificación de datos.\\n3.  **Comprensión del lenguaje natural**: Los embeddings se pueden utilizar para analizar y comprender el significado de los textos.\\n\\nEn resumen, los embeddings son una técnica utilizada en la inteligencia artificial y el aprendizaje automático que permite reducir la dimensionalidad de los datos originales y capturar su significado en un nuevo espacio de datos.', additional_kwargs={}, response_metadata={'model': 'llama3.2', 'created_at': '2025-02-13T03:01:30.1596519Z', 'done': True, 'done_reason': 'stop', 'total_duration': 49112257800, 'load_duration': 2563382900, 'prompt_eval_count': 66, 'prompt_eval_duration': 950378000, 'eval_count': 540, 'eval_duration': 45593623000, 'message': Message(role='assistant', content='', images=None, tool_calls=None)}, id='run-8d6941b5-83de-4e74-9937-6a1853afc697-0', usage_metadata={'input_tokens': 66, 'output_tokens': 540, 'total_tokens': 606})"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeloConHistorial.invoke(\n",
    "    {\"habilidad\" : \"inteligencia artificial\", \"entrada\" : \"Que son los embbedings?\"},\n",
    "    config={\"configurable\": {\"session_id\": \"12345\"}}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='¡Claro! Los embeddings son una técnica utilizada en inteligencia artificial para reducir la dimensionalidad de los datos originales y capturar su significado en un nuevo espacio de datos.\\n\\n**Características**\\n\\n1.  **Reducción de dimensionalidad**: Reduce la dimensión de los datos originales.\\n2.  **Representación de significado**: Intenta capturar el significado de los datos originales.\\n\\n**Tipos**\\n\\n1.  **Vector espacial**: Representa los datos como vectores en un espacio de dimensionalidad fija.\\n2.  **Eje espacial**: Busca minimizar la distancia entre dos puntos en el espacio de datos originales.\\n\\n**Aplicaciones**\\n\\n1.  **Reconocimiento de patrones**\\n2.  **Clasificación**\\n3.  **Comprensión del lenguaje natural**', additional_kwargs={}, response_metadata={'model': 'llama3.2', 'created_at': '2025-02-13T03:04:21.0086859Z', 'done': True, 'done_reason': 'stop', 'total_duration': 22040026500, 'load_duration': 20018200, 'prompt_eval_count': 627, 'prompt_eval_duration': 4565037000, 'eval_count': 187, 'eval_duration': 17445974000, 'message': Message(role='assistant', content='', images=None, tool_calls=None)}, id='run-a4ece7e9-265d-4a5a-9858-536edf08516d-0', usage_metadata={'input_tokens': 627, 'output_tokens': 187, 'total_tokens': 814})"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeloConHistorial.invoke(\n",
    "    {\"habilidad\" : \"inteligencia artificial\", \"entrada\" : \"Puedes ser volver a explicarlo con menos palabras?\"},\n",
    "    config={\"configurable\": {\"session_id\": \"12345\"}}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='¡Claro! Me especializo en inteligencia artificial y estaré aquí para ayudarte con cualquier pregunta o tema relacionado con ella. ¿En qué puedo ayudarte hoy?', additional_kwargs={}, response_metadata={'model': 'llama3.2', 'created_at': '2025-02-13T03:04:32.3665672Z', 'done': True, 'done_reason': 'stop', 'total_duration': 3694615900, 'load_duration': 19060100, 'prompt_eval_count': 71, 'prompt_eval_duration': 352538000, 'eval_count': 37, 'eval_duration': 3320732000, 'message': Message(role='assistant', content='', images=None, tool_calls=None)}, id='run-87ba896c-ee42-4653-a4ab-4102f86ef704-0', usage_metadata={'input_tokens': 71, 'output_tokens': 37, 'total_tokens': 108})"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modeloConHistorial.invoke(\n",
    "    {\"habilidad\" : \"inteligencia artificial\", \"entrada\" : \"Puedes ser volver a explicarlo con menos palabras?\"},\n",
    "    config={\"configurable\": {\"session_id\": \"123ab\"}}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'12345': InMemoryChatMessageHistory(messages=[HumanMessage(content='Que son los embbedings?', additional_kwargs={}, response_metadata={}), AIMessage(content='Los embeddings, también conocidos como vectores de representación o vectores de espacio de datos, son una técnica utilizada en la inteligencia artificial y el aprendizaje automático. Fue introducida por primera vez en 2013 por el equipo de researchers liderado por Quoc V. Le, durante su investigación sobre redes neuronales con convoluciones.\\n\\n**¿Qué es un embedding?**\\n\\nUn embedding es una transformación lineal que se aplica a un vector de entrada (como un documento de texto o una imagen) para reducir su dimensión a un espacio de datos más bajo y comprensible. En otras palabras, un embedding intenta capturar la esencia o el significado de los datos originales en un nuevo espacio de datos.\\n\\n**Características de los embeddings**\\n\\nLos embeddings tienen varias características importantes:\\n\\n1.  **Reducción de dimensionalidad**: Los embeddings reducen la dimensión de los datos originales, lo que hace más fácil el procesamiento y el almacenamiento de grandes conjuntos de datos.\\n2.  **Representación de significado**: Los embeddings intentan capturar el significado o la esencia de los datos originales en un nuevo espacio de datos.\\n3.  **Diferenciación**: Los embeddings son diferenciables, lo que significa que se puede calcular su derivada (gradiente) para minimizar una función de pérdida durante la entrenamiento.\\n\\n**Tipos de embeddings**\\n\\nExisten varios tipos de embeddings, incluyendo:\\n\\n1.  **Vector espacial**: Un tipo de embedding que representa los datos como vectores en un espacio de dimensionalidad fija.\\n2.  **Eje espacial**: Un tipo de embedding que busca minimizar la distancia entre dos puntos en el espacio de datos originales.\\n\\n**Aplicaciones de los embeddings**\\n\\nLos embeddings tienen muchas aplicaciones en el aprendizaje automático y otras áreas, incluyendo:\\n\\n1.  **Reconocimiento de patrones**: Los embeddings se pueden utilizar para reconocer patrones en grandes conjuntos de datos.\\n2.  **Clasificación**: Los embeddings se pueden utilizar como características para la clasificación de datos.\\n3.  **Comprensión del lenguaje natural**: Los embeddings se pueden utilizar para analizar y comprender el significado de los textos.\\n\\nEn resumen, los embeddings son una técnica utilizada en la inteligencia artificial y el aprendizaje automático que permite reducir la dimensionalidad de los datos originales y capturar su significado en un nuevo espacio de datos.', additional_kwargs={}, response_metadata={'model': 'llama3.2', 'created_at': '2025-02-13T03:01:30.1596519Z', 'done': True, 'done_reason': 'stop', 'total_duration': 49112257800, 'load_duration': 2563382900, 'prompt_eval_count': 66, 'prompt_eval_duration': 950378000, 'eval_count': 540, 'eval_duration': 45593623000, 'message': Message(role='assistant', content='', images=None, tool_calls=None)}, id='run-8d6941b5-83de-4e74-9937-6a1853afc697-0', usage_metadata={'input_tokens': 66, 'output_tokens': 540, 'total_tokens': 606}), HumanMessage(content='Puedes ser volver a explicarlo con menos palabras?', additional_kwargs={}, response_metadata={}), AIMessage(content='¡Claro! Los embeddings son una técnica utilizada en inteligencia artificial para reducir la dimensionalidad de los datos originales y capturar su significado en un nuevo espacio de datos.\\n\\n**Características**\\n\\n1.  **Reducción de dimensionalidad**: Reduce la dimensión de los datos originales.\\n2.  **Representación de significado**: Intenta capturar el significado de los datos originales.\\n\\n**Tipos**\\n\\n1.  **Vector espacial**: Representa los datos como vectores en un espacio de dimensionalidad fija.\\n2.  **Eje espacial**: Busca minimizar la distancia entre dos puntos en el espacio de datos originales.\\n\\n**Aplicaciones**\\n\\n1.  **Reconocimiento de patrones**\\n2.  **Clasificación**\\n3.  **Comprensión del lenguaje natural**', additional_kwargs={}, response_metadata={'model': 'llama3.2', 'created_at': '2025-02-13T03:04:21.0086859Z', 'done': True, 'done_reason': 'stop', 'total_duration': 22040026500, 'load_duration': 20018200, 'prompt_eval_count': 627, 'prompt_eval_duration': 4565037000, 'eval_count': 187, 'eval_duration': 17445974000, 'message': Message(role='assistant', content='', images=None, tool_calls=None)}, id='run-a4ece7e9-265d-4a5a-9858-536edf08516d-0', usage_metadata={'input_tokens': 627, 'output_tokens': 187, 'total_tokens': 814})]), '123ab': InMemoryChatMessageHistory(messages=[HumanMessage(content='Puedes ser volver a explicarlo con menos palabras?', additional_kwargs={}, response_metadata={}), AIMessage(content='¡Claro! Me especializo en inteligencia artificial y estaré aquí para ayudarte con cualquier pregunta o tema relacionado con ella. ¿En qué puedo ayudarte hoy?', additional_kwargs={}, response_metadata={'model': 'llama3.2', 'created_at': '2025-02-13T03:04:32.3665672Z', 'done': True, 'done_reason': 'stop', 'total_duration': 3694615900, 'load_duration': 19060100, 'prompt_eval_count': 71, 'prompt_eval_duration': 352538000, 'eval_count': 37, 'eval_duration': 3320732000, 'message': Message(role='assistant', content='', images=None, tool_calls=None)}, id='run-87ba896c-ee42-4653-a4ab-4102f86ef704-0', usage_metadata={'input_tokens': 71, 'output_tokens': 37, 'total_tokens': 108})])}\n"
     ]
    }
   ],
   "source": [
    "print(sesiones)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Herramientas (Tools)\n",
    "\n",
    "- Le permite a los modelos de lenguaje extender sus capacidades con funciones especificas.\n",
    "- Incluyen herramientas para busqueda, analasis y mas.\n",
    "- Integra APIs y servicioes externos para agregar funcionalidades."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install wikipedia -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools import WikipediaQueryRun\n",
    "from langchain_community.utilities import WikipediaAPIWrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_wrapper = WikipediaAPIWrapper(top_k_results=1, doc_content_chars_max=150)\n",
    "tool = WikipediaQueryRun(api_wrapper=api_wrapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'wikipedia'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A wrapper around Wikipedia. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects. Input should be a search query.'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool.description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': {'description': 'query to look up on wikipedia',\n",
       "  'title': 'Query',\n",
       "  'type': 'string'}}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool.args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Page: LangChain\\nSummary: LangChain is a software framework that helps facilitate the integration of large language models (LLMs) into applications. As'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool.run(\"Langchain\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install -q duckduckgo-search "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools import DuckDuckGoSearchResults\n",
    "\n",
    "search = DuckDuckGoSearchResults()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\edgar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\langchain_community\\utilities\\duckduckgo_search.py:64: UserWarning: backend='api' is deprecated, using backend='auto'\n",
      "  ddgs_gen = ddgs.text(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'snippet: Barack Obama has the highest favorability rating among all living presidents and Joe Biden has the lowest, according to a new Gallup poll released Tuesday. The results of a Gallup survey conducted ..., title: Obama has highest favorability rating of living presidents - POLITICO, link: https://www.politico.com/news/2025/02/11/barack-obama-joe-biden-favorability-00203578, snippet: Obama, in his remarks, insisted that he is \"convinced that if we want democracy as we understand it to survive,\" people must work for a renewed dedication to pluralist principles., title: Obama, in 1st remarks since election, says \\'a line has been ... - Fox News, link: https://www.foxnews.com/politics/obama-first-remarks-since-election-says-a-line-has-been-crossed-one-side-makes-certain-moves, snippet: Obama\\'s personal charisma, stirring oratory, and his campaign promise to bring change to the established political system resonated with many Democrats, especially young and minority voters. On January 3, 2008, Obama won a surprise victory in the first major nominating contest, the Iowa caucus, over Sen. Hillary Clinton, who was the overwhelming favorite to win the nomination., title: Barack Obama - 44th President, Political Career, Legacy | Britannica, link: https://www.britannica.com/biography/Barack-Obama/Politics-and-ascent-to-the-presidency, snippet: United States - Obama, Presidency, Reforms: The crisis worked against McCain, whom many voters associated with the unpopular policies of the administration, and worked for the highly charismatic Obama, whose campaign from its outset had been based on the theme of sweeping political change. Obama defeated McCain, becoming the first African American elected to the presidency. He captured nearly ..., title: United States - Obama, Presidency, Reforms | Britannica, link: https://www.britannica.com/place/United-States/The-Barack-Obama-administration'"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search.invoke(\"Obama\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> El uso de las herramientas nos permiten agregar diversas funcionalidades a nuestros programas, permitiendo que estos sean un poco mas concientes fuera de sus datos de entramiento. El uso y las herramientas que uno utilice, siempre dependeran del objetivo de nuestro programa.\n",
    ">\n",
    "> Es necesario tener en mente que aunque podemos agregar diversas funcionalidades y langchain es gratis, algunas herramientas no lo son, por lo que es necesario conocer la herramienta que deseamos utilizar, para asi, saber si son de paga o de libre acceso.\n",
    ">\n",
    "> Puedes consultar todas las herramientas de langchain pulsando [aqui](https://python.langchain.com/docs/integrations/tools/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
